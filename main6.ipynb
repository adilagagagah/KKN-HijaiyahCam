{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from shutil import copy2\n",
    "import ast\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pocketsphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag 1 : Classification Hijaiyah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_mapping.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Find the positions of the two dictionaries\n",
    "start1 = content.find('number_to_text')\n",
    "end1 = content.find('}', start1) + 1\n",
    "dict1_str = content[start1:end1]\n",
    "number_to_text = ast.literal_eval(dict1_str.split('=')[1].strip())\n",
    "\n",
    "start2 = content.find('lab_to_number')\n",
    "end2 = content.find('}', start2) + 1\n",
    "dict2_str = content[start2:end2]\n",
    "lab_to_number = ast.literal_eval(dict2_str.split('=')[1].strip())\n",
    "\n",
    "start3 = content.find('lab_to_text')\n",
    "end3 = content.find('}', start3) + 1\n",
    "dict3_str = content[start3:end3]\n",
    "lab_to_text = ast.literal_eval(dict3_str.split('=')[1].strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### menambahkan data baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_data_train(path_source, path_destination, exten_source, n_data, dict):\n",
    "    for label, text in dict.items():\n",
    "        # Regex pattern to match file names like {text}.jpg, {text}_1.jpg, {text}_2.jpg, etc.\n",
    "        pattern = re.compile(rf'^{text}(_\\d+)?\\.{exten_source}$')\n",
    "\n",
    "        # List all files in the source directory\n",
    "        files = os.listdir(path_source)\n",
    "        \n",
    "        # Filter files that match the pattern\n",
    "        matched_files = [f for f in files if pattern.match(f)]\n",
    "        \n",
    "        if not matched_files:\n",
    "            print(f\"No matching files found for pattern {text} in directory {path_source}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        for file in matched_files:\n",
    "            # Load the original image\n",
    "            img_path = os.path.join(path_source, file)\n",
    "            img = load_img(img_path, color_mode='rgb')  # Change color_mode if necessary\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "            # Create an ImageDataGenerator with augmentation options\n",
    "            datagen = ImageDataGenerator(\n",
    "                brightness_range=[0.2, 1.5],\n",
    "                rotation_range=30,      # Increase rotation range\n",
    "                shear_range=0.3,\n",
    "                zoom_range=0.1,         # Add zoom range\n",
    "                width_shift_range=0.1,  # Add width shift\n",
    "                height_shift_range=0.1, # Add height shift\n",
    "                fill_mode='nearest',    # Fill mode\n",
    "                validation_split=0.2    # Split validation\n",
    "            )\n",
    "        \n",
    "            # Generate augmented images\n",
    "            save_dir = os.path.join(path_destination, label)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "            i = 0\n",
    "            for batch in datagen.flow(img_array, batch_size=1, save_to_dir=save_dir, save_prefix='aug', save_format='png'):\n",
    "                i += 1\n",
    "                if i >= n_data:\n",
    "                    break\n",
    "                \n",
    "            print(f\"{n_data} augmented images for {text} have been saved to the '{save_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_data_train('data/example_1', 'data/hw_aug_digi', 'jpg', 600, lab_to_text)\n",
    "create_new_data_train('data/example_2', 'data/hw_aug_digi', 'jpg', 600, lab_to_text)\n",
    "create_new_data_train('data/example_3', 'data/hw_aug_digi', 'png', 600, lab_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memisahkan dataset sesuai label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memisahkan data di folder utama menjadi sub folder dengan warna tulisan hitam dan background putih\n",
    "source_folder = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "destination_folder = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Data_Train_Images\"\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "file_list = [f for f in os.listdir(source_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "for filename in file_list:\n",
    "    match = re.search(r'id_(\\d+)_label_(\\d+)', filename)\n",
    "    if match:\n",
    "        img_id = match.group(1)\n",
    "        label = match.group(2)\n",
    "        \n",
    "        # Membuat path folder label\n",
    "        label_folder = os.path.join(destination_folder, f'lab_{label}')\n",
    "        if not os.path.exists(label_folder):\n",
    "            os.makedirs(label_folder)\n",
    "        \n",
    "        # Memuat dan menginversi gambar\n",
    "        src_path = os.path.join(source_folder, filename)\n",
    "        img = Image.open(src_path)\n",
    "        img = ImageOps.invert(img)\n",
    "        \n",
    "        # Menyimpan gambar yang telah diubah ke folder tujuan dengan nama file baru\n",
    "        dest_path = os.path.join(label_folder, f'id_{img_id}.png')\n",
    "        img.save(dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan gambar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"data/hw_aug_digi\"\n",
    "images_per_row = 8\n",
    "size = 128\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'_(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "folders = [f for f in os.listdir(base_folder)]\n",
    "sorted_folders = sorted(folders, key=extract_number)\n",
    "\n",
    "for label in sorted_folders:\n",
    "    images_with_filenames = []\n",
    "    \n",
    "    label_directory = os.path.join(base_folder, label)\n",
    "    file_list = [f for f in os.listdir(label_directory) if f.endswith(\".png\")]\n",
    "    file_list.sort(key=extract_number)\n",
    "\n",
    "    for filename in file_list:\n",
    "        img_path = os.path.join(label_directory, filename)\n",
    "        img = Image.open(img_path).convert('L')  # Convert to grayscale if not already\n",
    "        img = img.resize((size, size))\n",
    "        img_array = np.array(img)\n",
    "        images_with_filenames.append((img_array, filename))\n",
    "\n",
    "    # Convert list of image arrays to a NumPy array\n",
    "    images = np.array([img[0] for img in images_with_filenames])\n",
    "    \n",
    "    print(f'Total data gambar: {len(images)}')\n",
    "    print(f'Shape setiap gambar: {images[0].shape}')\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, min(images_per_row, len(images)), figsize=(10, 1.5))\n",
    "    axes = axes.ravel()\n",
    "    for i in range(min(images_per_row, len(images))):\n",
    "        axes[i].imshow(images_with_filenames[i][0], cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(images_with_filenames[i][1], fontsize=8)\n",
    "\n",
    "    plt.suptitle(f'Label {lab_to_text[label]}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat model DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model_h5'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') > 0.90 and logs.get('val_accuracy') > 0.90:\n",
    "                print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "                print(f\"accuracy : {logs.get('accuracy') * 100:.2f}% \\n\"\n",
    "                      f\"val_acc : {logs.get('val_accuracy') * 100:.2f}% \\n\")\n",
    "                self.model.stop_training = True\n",
    "    \n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    rotation_range=5,      # Meningkatkan rotation range\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,         # Menambahkan zoom range\n",
    "    width_shift_range=0.1,  # Menambahkan width shift\n",
    "    height_shift_range=0.1, # Menambahkan height shift\n",
    "    fill_mode='nearest',    # Mode pengisian\n",
    "    validation_split=0.2    # Split validation\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=base_folder,\n",
    "    target_size=(size, size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    subset='training' \n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory=base_folder,\n",
    "    target_size=(size, size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(size, size, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(folders), activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_dir, 'model_5_{epoch:02d}_{accuracy:.2f}_{val_accuracy:.2f}.h5'), \n",
    "    monitor='val_accuracy',    # Metrik yang dipantau\n",
    "    save_best_only=True,       # Hanya menyimpan model terbaik\n",
    "    mode='max',                # Mode 'max' karena kita ingin akurasi maksimum\n",
    "    verbose=1                  # Menampilkan log setiap kali model disimpan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_generator:\n",
    "    plt.figure(figsize=(12, 3.3))\n",
    "    for i in range(16):\n",
    "        plt.subplot(2, 8, i+1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f'Label {number_to_text[labels[i].argmax()]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,        \n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint_callback, myCallback()]\n",
    ")\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation model\n",
    "\n",
    "size = (128,128)\n",
    "chanel = grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "def load_images_from_folders(base_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(base_folder)\n",
    "    \n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(base_folder, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            for filename in os.listdir(class_folder):\n",
    "                if filename.endswith(\".png\"):\n",
    "                    img_path = os.path.join(class_folder, filename)\n",
    "                    img_array = load_and_preprocess_image(img_path)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(class_index)\n",
    "    \n",
    "    images = np.vstack(images)  # Combine all images into one large array\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_names\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model_h5/model_5_02_0.91_0.98.h5')\n",
    "\n",
    "# Path to the dataset folder\n",
    "base_folder = 'data/hw_aug_digi'\n",
    "\n",
    "# Load and preprocess images\n",
    "images, true_labels, class_names = load_images_from_folders(base_folder)\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Display confusion matrix with new labels\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report with new labels\n",
    "print(classification_report(true_labels, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil satu batch gambar dan label dari generator\n",
    "for images, labels in train_generator:\n",
    "    # Melakukan prediksi dengan model\n",
    "    predictions = model.predict(images)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Membuat plot untuk menampilkan gambar dengan label asli dan prediksi\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    for i in range(16):\n",
    "        plt.subplot(2, 8, i+1)\n",
    "        plt.imshow(images[i].reshape(images[i].shape[0], images[i].shape[1]), cmap='gray')\n",
    "        plt.axis('off')        \n",
    "        plt.title(\"Label: {}\\nPrediction: {} \\n({:.1f}%)\".format(\n",
    "        number_to_text[labels[i].argmax()], \n",
    "        number_to_text[predicted_classes[i]], \n",
    "        np.max(predictions[i])*100\n",
    "    ))\n",
    "    \n",
    "    # Menampilkan plot\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coba pada data diluar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_h5/model_5_02_0.91_0.98.h5')\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = 'data/example_1'\n",
    "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.png', '.jpeg', '.jpg'))]\n",
    "\n",
    "for image_file in image_files:\n",
    "    img_array = load_and_preprocess_image(image_file)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    confidence = np.max(prediction) * 100\n",
    "\n",
    "    img = load_img(image_file, target_size=(size, size), color_mode='rgb')\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Prediction: {number_to_text[predicted_label]}, Confidence: {confidence:.2f}%')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubah model menjadi TfLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model Keras (.h5)\n",
    "model = load_model('model_h5/model_5_02_0.91_0.98.h5')\n",
    "\n",
    "# Konversi model ke format TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Simpan model TensorFlow Lite (.tflite)\n",
    "with open('model_tflite/model_5_02_0.91_0.98.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model berhasil dikonversi ke .tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buat prediksi dengan kamera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model_path = 'model_h5/model_5_02_0.91_0.98.h5'  # or 'model.tflite' if you are using TFLite\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Set up camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the size of the box for cropping\n",
    "box_size = (224, 224)  # Change this according to your model input size\n",
    "\n",
    "def preprocess_image(image, target_size=(128, 128)):\n",
    "    # Resize the image to the required size\n",
    "    image = cv2.resize(image, target_size)\n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Normalize the image if required by the model\n",
    "    image = image / 255.0\n",
    "    # Expand dimensions to match the model's input shape\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension for grayscale\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Define the box for cropping (centered)\n",
    "    height, width, _ = frame.shape\n",
    "    start_x = width // 2 - box_size[0] // 2\n",
    "    start_y = height // 2 - box_size[1] // 2\n",
    "    end_x = start_x + box_size[0]\n",
    "    end_y = start_y + box_size[1]\n",
    "\n",
    "    # Create a mask with the same dimensions as the frame\n",
    "    mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "    mask[start_y:end_y, start_x:end_x] = frame[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    # Create the darkened effect for the outside area\n",
    "    darkened_frame = frame.copy()\n",
    "    darkened_frame[:] = (50, 50, 50)  # Change this value to adjust the level of darkening\n",
    "\n",
    "    # Combine the original frame and the darkened frame using the mask\n",
    "    frame_with_effect = cv2.addWeighted(frame, 0.5, darkened_frame, 0.5, 0)\n",
    "    frame_with_effect[start_y:end_y, start_x:end_x] = frame[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    # Draw a rectangle around the area to be cropped\n",
    "    cv2.rectangle(frame_with_effect, (start_x, start_y), (end_x, end_y), (255, 255, 255), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame_with_effect)\n",
    "    \n",
    "    # Wait for 'c' key to be pressed to capture the image\n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        # Crop the image\n",
    "        cropped_image = frame[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # Preprocess the image\n",
    "        preprocessed_image = preprocess_image(cropped_image)\n",
    "        \n",
    "        # Make predictions\n",
    "        prediction = model.predict(preprocessed_image)\n",
    "    \n",
    "        predicted_label = np.argmax(prediction)\n",
    "        \n",
    "        # Print prediction\n",
    "        print(f\"Prediction: {number_to_text[predicted_label]}\")\n",
    "    \n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
