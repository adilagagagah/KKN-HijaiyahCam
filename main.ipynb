{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from shutil import copy2\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pocketsphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 0 : Trial n Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data gambar: 13440\n",
      "Shape setiap gambar: (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    \n",
    "    def extract_id(filename):\n",
    "        match = re.search(r'id_(\\d+)_', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "    \n",
    "    file_list = [f for f in os.listdir(folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    file_list.sort(key=extract_id)\n",
    "    \n",
    "    for filename in file_list:\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = Image.open(img_path).convert('RGB') \n",
    "        img = img.resize((128, 128))\n",
    "        img_array = np.array(img)\n",
    "        images.append((img_array, filename))\n",
    "    \n",
    "    return images\n",
    "\n",
    "folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "images_with_filenames = load_images_from_folder(folder_path)\n",
    "\n",
    "images = np.array([img[0] for img in images_with_filenames])\n",
    "filenames = [img[1] for img in images_with_filenames]\n",
    "\n",
    "print(f'Total data gambar: {len(images)}')\n",
    "print(f'Shape setiap gambar: {images[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan gambar berdasarkan label\n",
    "label_dict = {}\n",
    "for img_array, filename in images_with_filenames:\n",
    "    match = re.search(r'label_(\\d+)', filename)\n",
    "    if match:\n",
    "        label = int(match.group(1))\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = []\n",
    "        label_dict[label].append((img_array, filename))\n",
    "\n",
    "# Menampilkan gambar per label\n",
    "for label, images in label_dict.items():\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(10, 2))\n",
    "    axes = axes.ravel()\n",
    "    for i in range(min(8, len(images))):  # Hanya menampilkan maksimal 6 gambar per label\n",
    "        axes[i].imshow(images[i][0])\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(images[i][1], fontsize=8)\n",
    "    plt.suptitle(f'Label {label}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m base_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Data_Train_Images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m images, true_labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_from_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mload_images_from_folders\u001b[1;34m(base_folder)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     35\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_folder, filename)\n\u001b[1;32m---> 36\u001b[0m     _ , img_array \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(img_array)\n\u001b[0;32m     38\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(class_index)\n",
      "Cell \u001b[1;32mIn[8], line 46\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(img, target_size)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(img, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)):\n\u001b[1;32m---> 46\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)  \u001b[38;5;66;03m# Convert array to PIL Image\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(target_size)  \u001b[38;5;66;03m# Resize to target size\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "def create_folders_by_label(source_folder, destination_folder):\n",
    "    # Membuat folder tujuan jika belum ada\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    file_list = [f for f in os.listdir(source_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match = re.search(r'id_(\\d+)_label_(\\d+)', filename)\n",
    "        if match:\n",
    "            img_id = match.group(1)\n",
    "            label = match.group(2)\n",
    "            \n",
    "            # Membuat path folder label\n",
    "            label_folder = os.path.join(destination_folder, f'lab_{label}')\n",
    "            if not os.path.exists(label_folder):\n",
    "                os.makedirs(label_folder)\n",
    "            \n",
    "            # Menyalin file ke folder tujuan dengan nama file baru\n",
    "            src_path = os.path.join(source_folder, filename)\n",
    "            dest_path = os.path.join(label_folder, f'id_{img_id}.png')\n",
    "            copy2(src_path, dest_path)\n",
    "\n",
    "source_folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "destination_folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Data_Train_Images\"\n",
    "\n",
    "create_folders_by_label(source_folder_path, destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bag 1 : Classification Hijaiyah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def load_and_preprocess_image(img_path, target_size=(128, 128)):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "\n",
    "def load_images_from_folders(base_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_folder))\n",
    "    \n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(base_folder, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            for filename in os.listdir(class_folder):\n",
    "                if filename.endswith(\".png\"):\n",
    "                    img_path = os.path.join(class_folder, filename)\n",
    "                    img_array = load_and_preprocess_image(img_path)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(class_index)\n",
    "    \n",
    "    images = np.vstack(images)  # Combine all images into one large array\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, class_names\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model/model_38_0.86.h5')\n",
    "\n",
    "# Path to the dataset folder\n",
    "base_folder = 'data/Data_Train_Images'\n",
    "\n",
    "# Load and preprocess images\n",
    "images, true_labels, class_names = load_images_from_folders(base_folder)\n",
    "\n",
    "# Predict the class\n",
    "predictions = model.predict(images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Mapping from original class names to new labels\n",
    "label_mapping = {\n",
    "    'lab_1': 'alif',\n",
    "    'lab_2': 'ba',\n",
    "    'lab_3': 'ta',\n",
    "    'lab_4': 'tsa',\n",
    "    'lab_5': 'jim',\n",
    "    'lab_6': 'ha',\n",
    "    'lab_7': 'kho',\n",
    "    'lab_8': 'dal',\n",
    "    'lab_9': 'dzal',\n",
    "    'lab_10': 'ra',\n",
    "    'lab_11': 'zai',\n",
    "    'lab_12': 'sin',\n",
    "    'lab_13': 'syin',\n",
    "    'lab_14': 'shad',\n",
    "    'lab_15': 'dhad',\n",
    "    'lab_16': 'tha',\n",
    "    'lab_17': 'dha',\n",
    "    'lab_18': 'ain',\n",
    "    'lab_19': 'ghain',\n",
    "    'lab_20': 'fa',\n",
    "    'lab_21': 'qaf',\n",
    "    'lab_22': 'kaf',\n",
    "    'lab_23': 'lam',\n",
    "    'lab_24': 'mim',\n",
    "    'lab_25': 'nun',\n",
    "    'lab_26': 'ha',\n",
    "    'lab_27': 'waw',\n",
    "    'lab_28': 'ya'\n",
    "}\n",
    "\n",
    "# Ensure the class names are in the desired order\n",
    "class_names_sorted = sorted(class_names, key=lambda x: int(x.split('_')[1]))\n",
    "new_labels_sorted = [label_mapping[label] for label in class_names_sorted]\n",
    "\n",
    "# Display confusion matrix with new labels\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=new_labels_sorted, yticklabels=new_labels_sorted)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report with new labels\n",
    "print(classification_report(true_labels, predicted_classes, target_names=new_labels_sorted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 1 : Classification Hijaiyah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model/model_38_0.86.h5')\n",
    "\n",
    "# Mapping from original class names to new labels\n",
    "label_mapping = {\n",
    "    0: 'alif',\n",
    "    1: 'ba',\n",
    "    2: 'ta',\n",
    "    3: 'tsa',\n",
    "    4: 'jim',\n",
    "    5: 'ha',\n",
    "    6: 'kho',\n",
    "    7: 'dal',\n",
    "    8: 'dzal',\n",
    "    9: 'ra',\n",
    "    10: 'zai',\n",
    "    11: 'sin',\n",
    "    12: 'syin',\n",
    "    13: 'shad',\n",
    "    14: 'dhad',\n",
    "    15: 'tha',\n",
    "    16: 'dha',\n",
    "    17: 'ain',\n",
    "    18: 'ghain',\n",
    "    19: 'fa',\n",
    "    20: 'qaf',\n",
    "    21: 'kaf',\n",
    "    22: 'lam',\n",
    "    23: 'mim',\n",
    "    24: 'nun',\n",
    "    25: 'ha',\n",
    "    26: 'waw',\n",
    "    27: 'ya'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Path to the image file you want to predict\n",
    "image_path = 'data\\Data_Train_Images\\lab_1\\id_1.png'\n",
    "\n",
    "# Preprocess the image and get original image and numpy array\n",
    "original_image, preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Predict the class\n",
    "prediction = model.predict(preprocessed_image)\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "# Map the predicted class to the new label\n",
    "predicted_label = label_mapping[predicted_class]\n",
    "\n",
    "# Display the original image with prediction using Matplotlib\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(original_image)\n",
    "plt.axis('off')\n",
    "plt.title(f'Predicted: {predicted_label}', fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# Print original file name\n",
    "print(f'Original File Name: {image_path}')\n",
    "# Print predicted label\n",
    "print(f'Predicted Label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 2 : Recognize Doa Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
