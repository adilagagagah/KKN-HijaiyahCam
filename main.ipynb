{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from shutil import copy2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pocketsphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 0 : Trial n Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data gambar: 13440\n",
      "Shape setiap gambar: (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    \n",
    "    def extract_id(filename):\n",
    "        match = re.search(r'id_(\\d+)_', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "    \n",
    "    file_list = [f for f in os.listdir(folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    file_list.sort(key=extract_id)\n",
    "    \n",
    "    for filename in file_list:\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = Image.open(img_path).convert('RGB') \n",
    "        img = img.resize((128, 128))\n",
    "        img_array = np.array(img)\n",
    "        images.append((img_array, filename))\n",
    "    \n",
    "    return images\n",
    "\n",
    "folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "images_with_filenames = load_images_from_folder(folder_path)\n",
    "\n",
    "images = np.array([img[0] for img in images_with_filenames])\n",
    "filenames = [img[1] for img in images_with_filenames]\n",
    "\n",
    "print(f'Total data gambar: {len(images)}')\n",
    "print(f'Shape setiap gambar: {images[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan gambar berdasarkan label\n",
    "label_dict = {}\n",
    "for img_array, filename in images_with_filenames:\n",
    "    match = re.search(r'label_(\\d+)', filename)\n",
    "    if match:\n",
    "        label = int(match.group(1))\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = []\n",
    "        label_dict[label].append((img_array, filename))\n",
    "\n",
    "# Menampilkan gambar per label\n",
    "for label, images in label_dict.items():\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(10, 2))\n",
    "    axes = axes.ravel()\n",
    "    for i in range(min(8, len(images))):  # Hanya menampilkan maksimal 6 gambar per label\n",
    "        axes[i].imshow(images[i][0])\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(images[i][1], fontsize=8)\n",
    "    plt.suptitle(f'Label {label}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_by_label(source_folder, destination_folder):\n",
    "    # Membuat folder tujuan jika belum ada\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    file_list = [f for f in os.listdir(source_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match = re.search(r'id_(\\d+)_label_(\\d+)', filename)\n",
    "        if match:\n",
    "            img_id = match.group(1)\n",
    "            label = match.group(2)\n",
    "            \n",
    "            # Membuat path folder label\n",
    "            label_folder = os.path.join(destination_folder, f'lab_{label}')\n",
    "            if not os.path.exists(label_folder):\n",
    "                os.makedirs(label_folder)\n",
    "            \n",
    "            # Menyalin file ke folder tujuan dengan nama file baru\n",
    "            src_path = os.path.join(source_folder, filename)\n",
    "            dest_path = os.path.join(label_folder, f'id_{img_id}.png')\n",
    "            copy2(src_path, dest_path)\n",
    "\n",
    "source_folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "destination_folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Data_Train_Images\"\n",
    "\n",
    "create_folders_by_label(source_folder_path, destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 1 : Classification Hijaiyah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    TRAINING_DIR = \"data/rps\"\n",
    "    training_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=2,\n",
    "        shear_range=0.4\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "    # YOUR IMAGE SIZE SHOULD BE 150x150\n",
    "    # Make sure you used \"categorical\"\n",
    "    train_generator = training_datagen.flow_from_directory(\n",
    "        directory=TRAINING_DIR,\n",
    "        target_size=(150, 150),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        directory=TRAINING_DIR,\n",
    "        target_size=(150, 150),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "    # YOUR CODE HERE, end with 3 Neuron Dense, activated by softmax\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    callback = myCallback()\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load and preprocess dataset\n",
    "# ... (data loading and preprocessing steps)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(28, activation='softmax')  # Assuming 28 classes for Hijaiyah letters\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "# train_images, train_labels should be preprocessed datasets\n",
    "model.fit(datagen.flow(train_images, train_labels, batch_size=32), epochs=10, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Save the model\n",
    "model.save('hijaiyah_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 2 : Recognize Doa Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
