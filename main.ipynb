{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from shutil import copy2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pocketsphinx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 0 : Trial n Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data gambar: 13440\n",
      "Shape setiap gambar: (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    \n",
    "    def extract_id(filename):\n",
    "        match = re.search(r'id_(\\d+)_', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "    \n",
    "    file_list = [f for f in os.listdir(folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    file_list.sort(key=extract_id)\n",
    "    \n",
    "    for filename in file_list:\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = Image.open(img_path).convert('RGB') \n",
    "        img = img.resize((128, 128))\n",
    "        img_array = np.array(img)\n",
    "        images.append((img_array, filename))\n",
    "    \n",
    "    return images\n",
    "\n",
    "folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "images_with_filenames = load_images_from_folder(folder_path)\n",
    "\n",
    "images = np.array([img[0] for img in images_with_filenames])\n",
    "filenames = [img[1] for img in images_with_filenames]\n",
    "\n",
    "print(f'Total data gambar: {len(images)}')\n",
    "print(f'Shape setiap gambar: {images[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan gambar berdasarkan label\n",
    "label_dict = {}\n",
    "for img_array, filename in images_with_filenames:\n",
    "    match = re.search(r'label_(\\d+)', filename)\n",
    "    if match:\n",
    "        label = int(match.group(1))\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = []\n",
    "        label_dict[label].append((img_array, filename))\n",
    "\n",
    "# Menampilkan gambar per label\n",
    "for label, images in label_dict.items():\n",
    "    fig, axes = plt.subplots(1, 8, figsize=(10, 2))\n",
    "    axes = axes.ravel()\n",
    "    for i in range(min(8, len(images))):  # Hanya menampilkan maksimal 6 gambar per label\n",
    "        axes[i].imshow(images[i][0])\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(images[i][1], fontsize=8)\n",
    "    plt.suptitle(f'Label {label}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_by_label(source_folder, destination_folder):\n",
    "    # Membuat folder tujuan jika belum ada\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    file_list = [f for f in os.listdir(source_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match = re.search(r'id_(\\d+)_label_(\\d+)', filename)\n",
    "        if match:\n",
    "            img_id = match.group(1)\n",
    "            label = match.group(2)\n",
    "            \n",
    "            # Membuat path folder label\n",
    "            label_folder = os.path.join(destination_folder, f'lab_{label}')\n",
    "            if not os.path.exists(label_folder):\n",
    "                os.makedirs(label_folder)\n",
    "            \n",
    "            # Menyalin file ke folder tujuan dengan nama file baru\n",
    "            src_path = os.path.join(source_folder, filename)\n",
    "            dest_path = os.path.join(label_folder, f'id_{img_id}.png')\n",
    "            copy2(src_path, dest_path)\n",
    "\n",
    "source_folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Train Images 13440x32x32\\train\"\n",
    "destination_folder_path = r\"C:\\Users\\gagah\\Desktop\\KKN\\data\\Data_Train_Images\"\n",
    "\n",
    "create_folders_by_label(source_folder_path, destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 1 : Classification Hijaiyah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10752 images belonging to 28 classes.\n",
      "Found 2688 images belonging to 28 classes.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 126, 126, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 63, 63, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 61, 61, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 30, 30, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 14, 14, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 6, 6, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 42)                2730      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 28)                1204      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 699582 (2.67 MB)\n",
      "Trainable params: 699582 (2.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 2.5047 - accuracy: 0.2332\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41592, saving model to model\\model_01_0.42.h5\n",
      "336/336 [==============================] - 89s 259ms/step - loss: 2.5047 - accuracy: 0.2332 - val_loss: 1.8128 - val_accuracy: 0.4159\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagah\\Desktop\\KKN\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - ETA: 0s - loss: 1.5370 - accuracy: 0.5002\n",
      "Epoch 2: val_accuracy improved from 0.41592 to 0.57292, saving model to model\\model_02_0.57.h5\n",
      "336/336 [==============================] - 82s 243ms/step - loss: 1.5370 - accuracy: 0.5002 - val_loss: 1.3519 - val_accuracy: 0.5729\n",
      "Epoch 3/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 1.1111 - accuracy: 0.6310\n",
      "Epoch 3: val_accuracy improved from 0.57292 to 0.67485, saving model to model\\model_03_0.67.h5\n",
      "336/336 [==============================] - 88s 260ms/step - loss: 1.1111 - accuracy: 0.6310 - val_loss: 0.9827 - val_accuracy: 0.6749\n",
      "Epoch 4/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.8829 - accuracy: 0.7096\n",
      "Epoch 4: val_accuracy improved from 0.67485 to 0.70871, saving model to model\\model_04_0.71.h5\n",
      "336/336 [==============================] - 84s 251ms/step - loss: 0.8829 - accuracy: 0.7096 - val_loss: 0.8977 - val_accuracy: 0.7087\n",
      "Epoch 5/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.7343 - accuracy: 0.7576\n",
      "Epoch 5: val_accuracy improved from 0.70871 to 0.73400, saving model to model\\model_05_0.73.h5\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.7343 - accuracy: 0.7576 - val_loss: 0.8092 - val_accuracy: 0.7340\n",
      "Epoch 6/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.7939\n",
      "Epoch 6: val_accuracy improved from 0.73400 to 0.75521, saving model to model\\model_06_0.76.h5\n",
      "336/336 [==============================] - 84s 251ms/step - loss: 0.6242 - accuracy: 0.7939 - val_loss: 0.7715 - val_accuracy: 0.7552\n",
      "Epoch 7/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.8192\n",
      "Epoch 7: val_accuracy improved from 0.75521 to 0.77232, saving model to model\\model_07_0.77.h5\n",
      "336/336 [==============================] - 84s 250ms/step - loss: 0.5532 - accuracy: 0.8192 - val_loss: 0.6902 - val_accuracy: 0.7723\n",
      "Epoch 8/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.8393\n",
      "Epoch 8: val_accuracy improved from 0.77232 to 0.77902, saving model to model\\model_08_0.78.h5\n",
      "336/336 [==============================] - 94s 281ms/step - loss: 0.4811 - accuracy: 0.8393 - val_loss: 0.7315 - val_accuracy: 0.7790\n",
      "Epoch 9/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8523\n",
      "Epoch 9: val_accuracy did not improve from 0.77902\n",
      "336/336 [==============================] - 98s 291ms/step - loss: 0.4533 - accuracy: 0.8523 - val_loss: 0.6566 - val_accuracy: 0.7760\n",
      "Epoch 10/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8672\n",
      "Epoch 10: val_accuracy improved from 0.77902 to 0.79650, saving model to model\\model_10_0.80.h5\n",
      "336/336 [==============================] - 92s 275ms/step - loss: 0.3990 - accuracy: 0.8672 - val_loss: 0.6611 - val_accuracy: 0.7965\n",
      "Epoch 11/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8733\n",
      "Epoch 11: val_accuracy improved from 0.79650 to 0.80543, saving model to model\\model_11_0.81.h5\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.3717 - accuracy: 0.8733 - val_loss: 0.6402 - val_accuracy: 0.8054\n",
      "Epoch 12/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.8867\n",
      "Epoch 12: val_accuracy did not improve from 0.80543\n",
      "336/336 [==============================] - 85s 254ms/step - loss: 0.3440 - accuracy: 0.8867 - val_loss: 0.6356 - val_accuracy: 0.8017\n",
      "Epoch 13/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.8977\n",
      "Epoch 13: val_accuracy improved from 0.80543 to 0.81548, saving model to model\\model_13_0.82.h5\n",
      "336/336 [==============================] - 88s 263ms/step - loss: 0.3091 - accuracy: 0.8977 - val_loss: 0.6345 - val_accuracy: 0.8155\n",
      "Epoch 14/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.9048\n",
      "Epoch 14: val_accuracy did not improve from 0.81548\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.2902 - accuracy: 0.9048 - val_loss: 0.8794 - val_accuracy: 0.7701\n",
      "Epoch 15/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9094\n",
      "Epoch 15: val_accuracy did not improve from 0.81548\n",
      "336/336 [==============================] - 85s 252ms/step - loss: 0.2709 - accuracy: 0.9094 - val_loss: 0.6453 - val_accuracy: 0.8092\n",
      "Epoch 16/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.9182\n",
      "Epoch 16: val_accuracy improved from 0.81548 to 0.82292, saving model to model\\model_16_0.82.h5\n",
      "336/336 [==============================] - 85s 254ms/step - loss: 0.2448 - accuracy: 0.9182 - val_loss: 0.6925 - val_accuracy: 0.8229\n",
      "Epoch 17/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9170\n",
      "Epoch 17: val_accuracy improved from 0.82292 to 0.82961, saving model to model\\model_17_0.83.h5\n",
      "336/336 [==============================] - 85s 252ms/step - loss: 0.2412 - accuracy: 0.9170 - val_loss: 0.6155 - val_accuracy: 0.8296\n",
      "Epoch 18/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9269\n",
      "Epoch 18: val_accuracy did not improve from 0.82961\n",
      "336/336 [==============================] - 84s 250ms/step - loss: 0.2241 - accuracy: 0.9269 - val_loss: 0.6697 - val_accuracy: 0.8225\n",
      "Epoch 19/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9243\n",
      "Epoch 19: val_accuracy improved from 0.82961 to 0.83110, saving model to model\\model_19_0.83.h5\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.2221 - accuracy: 0.9243 - val_loss: 0.6636 - val_accuracy: 0.8311\n",
      "Epoch 20/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9358\n",
      "Epoch 20: val_accuracy improved from 0.83110 to 0.83259, saving model to model\\model_20_0.83.h5\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.2007 - accuracy: 0.9358 - val_loss: 0.6079 - val_accuracy: 0.8326\n",
      "Epoch 21/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.9364\n",
      "Epoch 21: val_accuracy did not improve from 0.83259\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.1866 - accuracy: 0.9364 - val_loss: 0.5901 - val_accuracy: 0.8292\n",
      "Epoch 22/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9441\n",
      "Epoch 22: val_accuracy did not improve from 0.83259\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.1675 - accuracy: 0.9441 - val_loss: 0.6609 - val_accuracy: 0.8322\n",
      "Epoch 23/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9476\n",
      "Epoch 23: val_accuracy did not improve from 0.83259\n",
      "336/336 [==============================] - 84s 250ms/step - loss: 0.1604 - accuracy: 0.9476 - val_loss: 0.7339 - val_accuracy: 0.8162\n",
      "Epoch 24/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9511\n",
      "Epoch 24: val_accuracy improved from 0.83259 to 0.84152, saving model to model\\model_24_0.84.h5\n",
      "336/336 [==============================] - 84s 250ms/step - loss: 0.1456 - accuracy: 0.9511 - val_loss: 0.6000 - val_accuracy: 0.8415\n",
      "Epoch 25/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9482\n",
      "Epoch 25: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 85s 253ms/step - loss: 0.1562 - accuracy: 0.9482 - val_loss: 0.7158 - val_accuracy: 0.8337\n",
      "Epoch 26/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9486\n",
      "Epoch 26: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.1500 - accuracy: 0.9486 - val_loss: 0.7250 - val_accuracy: 0.8281\n",
      "Epoch 27/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9512\n",
      "Epoch 27: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.1445 - accuracy: 0.9512 - val_loss: 0.7054 - val_accuracy: 0.8229\n",
      "Epoch 28/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9589\n",
      "Epoch 28: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 84s 251ms/step - loss: 0.1256 - accuracy: 0.9589 - val_loss: 0.7158 - val_accuracy: 0.8263\n",
      "Epoch 29/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9553\n",
      "Epoch 29: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 85s 252ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.7581 - val_accuracy: 0.8318\n",
      "Epoch 30/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9576\n",
      "Epoch 30: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.1209 - accuracy: 0.9576 - val_loss: 0.7163 - val_accuracy: 0.8408\n",
      "Epoch 31/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9605\n",
      "Epoch 31: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 84s 250ms/step - loss: 0.1137 - accuracy: 0.9605 - val_loss: 0.8119 - val_accuracy: 0.8326\n",
      "Epoch 32/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9617\n",
      "Epoch 32: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 87s 257ms/step - loss: 0.1155 - accuracy: 0.9617 - val_loss: 0.7960 - val_accuracy: 0.8337\n",
      "Epoch 33/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9645\n",
      "Epoch 33: val_accuracy did not improve from 0.84152\n",
      "336/336 [==============================] - 83s 247ms/step - loss: 0.1071 - accuracy: 0.9645 - val_loss: 0.7511 - val_accuracy: 0.8341\n",
      "Epoch 34/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9631\n",
      "Epoch 34: val_accuracy improved from 0.84152 to 0.84412, saving model to model\\model_34_0.84.h5\n",
      "336/336 [==============================] - 84s 250ms/step - loss: 0.1070 - accuracy: 0.9631 - val_loss: 0.7630 - val_accuracy: 0.8441\n",
      "Epoch 35/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9663\n",
      "Epoch 35: val_accuracy did not improve from 0.84412\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.1054 - accuracy: 0.9663 - val_loss: 0.7416 - val_accuracy: 0.8415\n",
      "Epoch 36/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9677\n",
      "Epoch 36: val_accuracy did not improve from 0.84412\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.0985 - accuracy: 0.9677 - val_loss: 0.8008 - val_accuracy: 0.8385\n",
      "Epoch 37/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9692\n",
      "Epoch 37: val_accuracy did not improve from 0.84412\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.0916 - accuracy: 0.9692 - val_loss: 0.7609 - val_accuracy: 0.8400\n",
      "Epoch 38/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9701\n",
      "Epoch 38: val_accuracy improved from 0.84412 to 0.85603, saving model to model\\model_38_0.86.h5\n",
      "336/336 [==============================] - 83s 247ms/step - loss: 0.0943 - accuracy: 0.9701 - val_loss: 0.6721 - val_accuracy: 0.8560\n",
      "Epoch 39/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9701\n",
      "Epoch 39: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 247ms/step - loss: 0.0860 - accuracy: 0.9701 - val_loss: 0.8037 - val_accuracy: 0.8434\n",
      "Epoch 40/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9723\n",
      "Epoch 40: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.0833 - accuracy: 0.9723 - val_loss: 0.7260 - val_accuracy: 0.8478\n",
      "Epoch 41/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9746\n",
      "Epoch 41: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.0761 - accuracy: 0.9746 - val_loss: 0.8815 - val_accuracy: 0.8475\n",
      "Epoch 42/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9706\n",
      "Epoch 42: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.0859 - accuracy: 0.9706 - val_loss: 0.7615 - val_accuracy: 0.8486\n",
      "Epoch 43/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9698\n",
      "Epoch 43: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 247ms/step - loss: 0.0881 - accuracy: 0.9698 - val_loss: 0.8180 - val_accuracy: 0.8356\n",
      "Epoch 44/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9721\n",
      "Epoch 44: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 82s 245ms/step - loss: 0.0858 - accuracy: 0.9721 - val_loss: 0.6660 - val_accuracy: 0.8549\n",
      "Epoch 45/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9745\n",
      "Epoch 45: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 248ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.8585 - val_accuracy: 0.8393\n",
      "Epoch 46/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9743\n",
      "Epoch 46: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 84s 248ms/step - loss: 0.0773 - accuracy: 0.9743 - val_loss: 0.8054 - val_accuracy: 0.8445\n",
      "Epoch 47/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9733\n",
      "Epoch 47: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 84s 248ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.7444 - val_accuracy: 0.8371\n",
      "Epoch 48/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9723\n",
      "Epoch 48: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 246ms/step - loss: 0.0838 - accuracy: 0.9723 - val_loss: 0.7132 - val_accuracy: 0.8438\n",
      "Epoch 49/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9793\n",
      "Epoch 49: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 84s 249ms/step - loss: 0.0630 - accuracy: 0.9793 - val_loss: 0.8869 - val_accuracy: 0.8352\n",
      "Epoch 50/50\n",
      "336/336 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9799\n",
      "Epoch 50: val_accuracy did not improve from 0.85603\n",
      "336/336 [==============================] - 83s 247ms/step - loss: 0.0613 - accuracy: 0.9799 - val_loss: 0.9195 - val_accuracy: 0.8356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14ba3f77eb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DIR = destination_folder_path\n",
    "\n",
    "model_dir = 'model'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=2,\n",
    "    shear_range=0.4, \n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=TRAINING_DIR,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training' \n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory=TRAINING_DIR,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(42, activation='relu'),\n",
    "    tf.keras.layers.Dense(28, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_dir, 'model_{epoch:02d}_{val_accuracy:.2f}.h5'),  # Nama file dengan epoch dan akurasi validasi\n",
    "    monitor='val_accuracy',    # Metrik yang dipantau\n",
    "    save_best_only=True,       # Hanya menyimpan model terbaik\n",
    "    mode='max',                # Mode 'max' karena kita ingin akurasi maksimum\n",
    "    verbose=1                  # Menampilkan log setiap kali model disimpan\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag 2 : Recognize Doa Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
